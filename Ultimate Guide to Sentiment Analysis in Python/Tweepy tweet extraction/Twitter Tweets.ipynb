{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Extraction using tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets install the tweepy library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import the libraries and authorize our connection with the API with the keys we obtained in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tweepy\n",
    "\n",
    "import tweepy as tw\n",
    "\n",
    "# your Twitter API key and API secret\n",
    "my_api_key = \"XXXXXXXXXXXXXXXXX\"\n",
    "my_api_secret = \"XXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "# authenticate our credentials to login\n",
    "\n",
    "autho = tw.OAuthHandler(my_api_key, my_api_secret)\n",
    "api = tw.API(autho, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set a search query, this is the hashtag we want to search our tweets from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"#christmas -filter:retweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Tweepy Cursor to fetch the tweets.\n",
    "\n",
    "It returns an object which can be iterated over to get the API responses. \n",
    "\n",
    "We will be fetching 50 tweets for the search query specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweets from the API\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2020-09-16\").items(50)\n",
    "\n",
    "# store the API responses in a list\n",
    "\n",
    "tweets_copy = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweets_copy.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we pass as an argument the api.search object, the search query, the language of the tweets, and the date from which to search the tweets.\n",
    "We also limit the number of items (i.e. tweets in this case to 50). The responses are iterated over and saved to the list tweets_copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a dataset (a pandas dataframe) using the attributes of the tweets received from the API, so that we can use our collected data to use for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# intialize the dataframe\n",
    "tweets_df = pd.DataFrame()\n",
    "\n",
    "# populate the dataframe\n",
    "for tweet in tweets_copy:\n",
    "    hashtags = []\n",
    "    try:\n",
    "        for hashtag in tweet.entities[\"hashtags\"]:\n",
    "            hashtags.append(hashtag[\"text\"])\n",
    "        text = api.get_status(id=tweet.id, tweet_mode='extended').full_text\n",
    "    except:\n",
    "        pass\n",
    "    tweets_df = tweets_df.append(pd.DataFrame({'user_name': tweet.user.name, \n",
    "                                               'user_location': tweet.user.location,\\\n",
    "                                               'user_description': tweet.user.description,\n",
    "                                               'user_verified': tweet.user.verified,\n",
    "                                               'date': tweet.created_at,\n",
    "                                               'text': text, \n",
    "                                               'hashtags': [hashtags if hashtags else None],\n",
    "                                               'source': tweet.source}))\n",
    "    tweets_df = tweets_df.reset_index(drop=True)\n",
    "\n",
    "# show the dataframe\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dataframe tweets_df is populated with different attributes of the Tweet like the username, user’s location, the user’s description, tweet’s timing, tweet’s text, hashtag, etc.\n",
    "\n",
    "Also, note that for the tweet’s text we’re not using tweet.text rather we’re calling the API again with the tweet id and fetching its full text. This is because tweet.text does not contain the full text of the Tweet.\n",
    "\n",
    "Having the data stored as a dataframe is quite useful for further analysis and reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
